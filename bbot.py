import os
import json
from datetime import datetime
from typing import List
from typing_extensions import TypedDict
from pydantic import BaseModel
from dotenv import load_dotenv

import psycopg2
from openai import OpenAI
from langchain_upstage import UpstageEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from tiktoken import encoding_for_model
import tiktoken




# .env íŒŒì¼ ë¡œë“œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
load_dotenv()   
api_key = os.getenv("UPSTAGE_API_KEY")
base_url = os.getenv("UPSTAGE_BASE_URL")




# Upstage ëª¨ë¸ ìƒì„± 
model = OpenAI(api_key=api_key, base_url=base_url)
embedding_model = UpstageEmbeddings(
    upstage_api_key=api_key,
    model="embedding-query"
)



# DB ìƒì„± ë° ë¬¸ì„œ ì²˜ë¦¬
enc = tiktoken.get_encoding("cl100k_base")     # tokenizer

def count_tokens(text: str) -> int:            # í† í° ìˆ˜ ì„¸ê¸°
    return len(enc.encode(text))               # í† í° ìˆ˜ ë°˜í™˜

def split_text_by_tokens(text: str, max_tokens: int = 4000):
    words = text.split()                           
    chunks = []                
    chunk = []                            
    tokens_so_far = 0                  

    for word in words:                   
        word_tokens = count_tokens(word + " ")     
        if tokens_so_far + word_tokens > max_tokens:     
            chunks.append(" ".join(chunk))        
            chunk = []                                        
            tokens_so_far = 0             
        chunk.append(word)                         
        tokens_so_far += word_tokens            

    if chunk:                                     
        chunks.append(" ".join(chunk))             
    return chunks                             


def create_db(folder_path: str, db_name: str = "bbot_db", max_tokens: int = 4000):
    """extracted_texts í´ë” ì•ˆ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì„ë² ë”©í•˜ì—¬ DBì— ì €ì¥"""

    # PostgreSQL ì—°ê²°
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST"),                 # PostgreSQL í˜¸ìŠ¤íŠ¸
        dbname=db_name,                            # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        user=os.getenv("DB_USER"),                 # ì‚¬ìš©ì ì´ë¦„
        password=os.getenv("DB_PASSWORD"),         # ë¹„ë°€ë²ˆí˜¸
        port=os.getenv("DB_PORT")                  # í¬íŠ¸ ë²ˆí˜¸
    )
    cur = conn.cursor()                            # ì»¤ì„œ ìƒì„±
    print("[DB] ì—°ê²° ì„±ê³µ")                          # ì—°ê²° ì„±ê³µ ì½˜ì†” ë©”ì‹œì§€ ì¶œë ¥

    # pgvector í™•ì¥ 
    cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    # í…Œì´ë¸” ìƒì„± (id, title, url, crawl_time, content, content_embedding)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS crawled_data (  
            id SERIAL PRIMARY KEY,
            title TEXT,
            url TEXT,
            crawl_time TIMESTAMP,
            content TEXT,
            content_embedding vector(4096)
        );
    """)

    # failed files ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    failed_files = []
    # ì‚½ì…ëœ ì²­í¬ ìˆ˜ ì¹´ìš´íŠ¸
    inserted_count = 0

    # í´ë” ë‚´ ëª¨ë“  .txt íŒŒì¼ ì²˜ë¦¬ (í¬ë¡¤ë§ëœ ë°ì´í„° - ì°½ì¡°ê³¼í•™ì‚¬ì´íŠ¸)
    files = [f for f in os.listdir(folder_path) if f.endswith(".txt")]
    # í´ë” ë‚´ íŒŒì¼ ê°œìˆ˜ ì¶œë ¥
    print(f"[DB] í´ë”ì—ì„œ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")

    # ê° íŒŒì¼ ì²˜ë¦¬
    for idx, fname in enumerate(files, start=1):
        try:
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(os.path.join(folder_path, fname), "r", encoding="utf-8") as f:
                content = f.read()

            # ê¸¸ë©´ ì²­í¬ë¡œ ë¶„í• 
            chunks = split_text_by_tokens(content, max_tokens=max_tokens)

            # ê° ì²­í¬ë¥¼ DBì— ì‚½ì…
            for chunk in chunks:
                title = fname.replace(".txt", "")
                url = ""
                crawl_time = datetime.now()

                embedding_vector = embedding_model.embed_query(chunk)

                cur.execute(
                    "INSERT INTO crawled_data (title, url, crawl_time, content, content_embedding) VALUES (%s, %s, %s, %s, %s::vector)",
                    (title, url, crawl_time, chunk, embedding_vector)
                )
                inserted_count += 1

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if idx % 100 == 0:
                print(f"[DB] {idx}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

        # ì˜ˆì™¸ ì²˜ë¦¬
        except Exception as e:
            # ì‹¤íŒ¨ëœ íŒŒì¼ ê¸°ë¡ ë° ë¡¤ë°±
            print(f"[ERROR] íŒŒì¼ ì‚½ì… ì‹¤íŒ¨: {fname} / {e}")
            failed_files.append(fname)
            conn.rollback()

    # ë³€ê²½ì‚¬í•­ ì»¤ë°‹
    conn.commit()

    # ìµœì¢… í†µê³„ ì¶œë ¥
    cur.execute("SELECT COUNT(*) FROM crawled_data;")
    total_count = cur.fetchone()[0]
    print(f"[DB] ì´ ë°ì´í„° ê°œìˆ˜: {total_count}")
    print(f"[DB] ì„±ê³µì ìœ¼ë¡œ ì‚½ì…ëœ ì²­í¬ ìˆ˜: {inserted_count}")
    print(f"[DB] ì‹¤íŒ¨í•œ íŒŒì¼ ìˆ˜: {len(failed_files)}")
    if failed_files:
        print("[DB] ì‹¤íŒ¨í•œ íŒŒì¼ ì¼ë¶€:", failed_files[:20])

    # ì—°ê²° ì¢…ë£Œ
    cur.close()
    conn.close()
    # ë°ì´í„° ì‚½ì… ì™„ë£Œ ë©”ì„¸ì§€ ì¶œë ¥ 
    print("[DB] ë°ì´í„° ì‚½ì… ì™„ë£Œ")




# ë¼ìš°í„°
def router(question: str) -> str:
    """
    ì°½ì¡°ê³¼í•™/ì„±ê²½/ê¸°ë…êµ ì§ˆë¬¸ë§Œ í—ˆìš©
    ì¼ë°˜ ìƒì‹ ì§ˆë¬¸ì€ ê±°ì ˆ
    """
    print("[Router] ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì¤‘...")

    keywords = ["ì°½ì¡°", "ì„±ê²½", "í•˜ë‚˜ë‹˜", "ì§„í™”", "ë³µìŒ", "ì•„ë‹´", "ë…¸ì•„", "ëŒ€í™ìˆ˜", "ì°½ì„¸ê¸°", "ê¸°ë…êµ", "ì„¸ê³„ê´€", "ë¯¿ìŒ", "ì˜ˆìˆ˜ë‹˜", "êµ¬ì›"]
    decision = "internal" if any(k in question for k in keywords) else "internal"

    print(f"[Router] ì„ íƒëœ ê²½ë¡œ: {decision}")
    return decision




# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ 
def retrieve_documents(question: str, top_k: int = 5):
    print("[Retrieve] ë²¡í„° ê²€ìƒ‰ ì‹œì‘")

    # ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
    q_embedding = embedding_model.embed_query(question)

    # PostgreSQL ì—°ê²°
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST"),
        dbname=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        port=os.getenv("DB_PORT")
    )
    # ì»¤ì„œ ìƒì„±
    cur = conn.cursor()

    # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
    cur.execute("""
        SELECT title, url, content
        FROM crawled_data
        ORDER BY content_embedding <#> %s::vector
        LIMIT %s
    """, (q_embedding, top_k))

    # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    rows = cur.fetchall()
    # ì—°ê²° ì¢…ë£Œ
    cur.close()
    conn.close()

    # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    docs = [
        {"title": r[0], "url": r[1], "content": r[2]}
        for r in rows
    ]

    # ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ ì¶œë ¥
    print(f"[Retrieve] ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(docs)}")

    # ê° ë¬¸ì„œ ì •ë³´ ì¶œë ¥ (ë¯¸ë¦¬ë³´ê¸°)
    for i, d in enumerate(docs, start=1):
        print(f"\n[Doc {i}]")
        print(f"Title: {d['title']}")
        print(f"URL: {d['url']}")
        print(f"Content (preview): {d['content'][:300]}")  # ì• 300ìë§Œ

    # ë¬¸ì„œ ë°˜í™˜
    return docs



# ê²€ìƒ‰ ê²°ê³¼ íŒë‹¨ (Judge)
# ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ì— ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ íŒë‹¨
class RetrievalJudge(BaseModel):
    judgement: str
    binary_score: str

def judge_retrieval(question: str, docs: List[dict]) -> RetrievalJudge:
    print("[Judge] ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ì¤‘...")

    # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë°”ë¡œ not_resolved ë°˜í™˜
    if not docs:
        return RetrievalJudge(judgement="not_resolved", binary_score="no")

    # ë¬¸ì„œ ë‚´ìš© 500ìì”© ê²°í•©
    joined_docs = "\n".join(d["content"][:500] for d in docs)

    prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ë¬¸ì„œë“¤ì´ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

    Question:
    {question}

    Documents:
    {joined_docs}

    JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
    {{
        "judgement": "resolved" or "not_resolved",
        "binary_score": "yes" or "no"
    }}
    """

    # LLM í˜¸ì¶œ
    res = model.chat.completions.create(
        model="solar-pro2",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
    content = res.choices[0].message.content

    # JSON íŒŒì‹±
    try:
        # JSON ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
        json_start = content.find("{")
        if json_start == -1:
            raise ValueError("JSON not found in LLM response")
        json_obj = json.loads(content[json_start:])
        result = RetrievalJudge(**json_obj)
    except (json.JSONDecodeError, ValueError) as e:
        print(f"[Judge] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        result = RetrievalJudge(judgement="not_resolved", binary_score="no")

    print(f"[Judge] íŒë‹¨ ê²°ê³¼: {result.judgement}")
    return result




# ì§ˆë¬¸ ì¬ì‘ì„± (Rewriter)
# ì§ˆë¬¸ì„ ì¬ì‘ì„±í•¨ìœ¼ë¡œì¨ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ 
system_rewriter = """
ë‹¹ì‹ ì€ RAG ê²€ìƒ‰ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ë” ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì¬ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
"""

# "ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ ë” ì˜ ì“°ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤" ê°™ì€ ì§€ì¹¨ì´ ë“¤ì–´ ìˆìŒ
prompt_rewriter = ChatPromptTemplate.from_messages([
    ("system", system_rewriter),
    ("human", "Original question: {question}")
])

def rewrite_query(question: str) -> str:
    print("[Rewrite] ì§ˆë¬¸ ì¬ì‘ì„± ì¤‘...")

    # ì§ˆë¬¸ ì¬ì‘ì„± ì²´ì¸ 
    chain = (
        # 1) prompt_rewriter (system + human í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)
        prompt_rewriter
        # 2) LLM(solar-pro2)ì„ í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„
        | RunnableLambda(
            lambda p: model.chat.completions.create(
                model="solar-pro2",
                messages=[{"role": "user", "content": p.to_string()}],
                temperature=0
            ).choices[0].message.content
        )
        # 3) LLM ì¶œë ¥ ê²°ê³¼ë¥¼ ë¬¸ìì—´(str)ë¡œ ì •ë¦¬í•˜ëŠ” ë¶€ë¶„
        | StrOutputParser()
    )
    # ì²´ì¸ ì‹¤í–‰
    rewritten = chain.invoke({"question": question})
    print(f"[Rewrite] ì¬ì‘ì„±ëœ ì§ˆë¬¸: {rewritten}")
    return rewritten



# ë‹µë³€ ìƒì„± 
def detect_language(text: str) -> str:         # ì–¸ì–´ ê°ì§€ 
    return "ko" if any('\uac00' <= ch <= '\ud7a3' for ch in text) else "en"

def build_context(docs: list[dict]) -> str:    # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    return "\n\n".join(
        f"[ë¬¸ì„œ]\nì œëª©: {d['title']}\në‚´ìš©: {d['content']}\nURL: {d['url']}"
        for d in docs
    )


def generate_answer(question: str, docs: list[dict]) -> str:
    if not docs:
        return "ì œê³µëœ ë¬¸ì„œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    lang = detect_language(question)
    context = build_context(docs)

    lang_instruction = (
        "í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”." if lang == "ko"
        else "Answer in English."
    )

    system_prompt = f"""
    ë‹¹ì‹ ì€ ê¸°ë…êµì  ì„¸ê³„ê´€ê³¼ ì°½ì¡°ë¡ ì— ê¸°ë°˜í•´ ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    â—ê·œì¹™ (ì ˆëŒ€ ìœ„ë°˜ ê¸ˆì§€):
    - ë°˜ë“œì‹œ ì œê³µëœ [ë¬¸ì„œ] ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
    - ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.
    - ì¶”ì¸¡, ì¼ë°˜ ìƒì‹, ì‚¬ì „ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€
    - ë‹µë³€ ë§ˆì§€ë§‰ì— ì‚¬ìš©í•œ ë¬¸ì„œì˜ URLì„ ëª¨ë‘ ë‚˜ì—´í•˜ì„¸ìš”.
    - ì›¹ ê²€ìƒ‰ì€ ì„±ê²½ êµ¬ì ˆì„ ì°¾ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

    âœï¸ ë‹µë³€ í˜•ì‹:
    - ğŸ”¬ ê³¼í•™ì  ê´€ì 
    - ğŸ“– ì„±ê²½ì  ê´€ì 
    - ğŸ”— ì°¸ê³  ë¬¸ì„œ URL

    {lang_instruction}
    """

    user_prompt = f"""
    [ë¬¸ì„œ]
    {context}

    [ì§ˆë¬¸]
    {question}

    ìœ„ ë¬¸ì„œì— ê·¼ê±°í•´ ë‹µë³€í•˜ì„¸ìš”.
    """

    res = model.chat.completions.create(
        model="solar-pro2",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0
    )

    return res.choices[0].message.content




# Main agent
def generate(question: str) -> str:
    # ì½˜ì†” ë©”ì„¸ì§€ ì¶œë ¥ìœ¼ë¡œ ì‹œì‘ 
    print("\n===== NEW QUERY =====")
    # ìœ ì € ë©”ì„¸ì§€ ì¶œë ¥ 
    print(f"User Question: {question}")

    # ë¼ìš°í„° í˜¸ì¶œ (ì°½ì¡°ê³¼í•™/ì„±ê²½ ì§ˆë¬¸ë§Œ í—ˆìš©)
    route = router(question)

    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ 
    docs = retrieve_documents(question)
    # ê²€ìƒ‰ëœ ë¬¸ì„œ íŒë‹¨ 
    judge = judge_retrieval(question, docs)

    # íŒë‹¨ ê²°ê³¼ì— ë”°ë¼ ì§ˆë¬¸ ì¬ì‘ì„± ë° ì¬ê²€ìƒ‰ 
    if judge.judgement == "not_resolved":
        new_question = rewrite_query(question)
        docs = retrieve_documents(new_question)

    # ìµœì¢… ë‹µë³€ ìƒì„± (ë¬¸ì„œ ê¸°ë°˜)
    answer = generate_answer(question, docs)
    # ë§ˆì§€ë§‰ ì½˜ì†” ì¶œë ¥ 
    print("[Done] ì‘ë‹µ ì™„ë£Œ\n")
    return answer